{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "zVGeBEFhpsJ2",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 - Shubhra Das**\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project explores and models Zomato restaurant data using two CSV files: one with restaurant names and metadata, and another with detailed customer reviews.\n",
        "The overall objective is twofold:\n",
        "\n",
        "a) perform structured Exploratory Data Analysis (EDA) to understand patterns in restaurant characteristics and customer behaviour, and\n",
        "\n",
        "b)build a machine learning classification model that predicts review sentiment (positive vs. non-positive) using review text and selected restaurant attributes.\n",
        "\n",
        "Work begins in Google Colab with data loading, inspection, and cleaning. Both datasets are checked for data types, missing values, and duplicates. The metadata file is cleaned by standardising the “Cost” column into a numeric cost_for_two feature, normalising cuisine strings, and handling the single missing timing entry. The reviews dataset is cleaned by dropping rows with missing essential fields (review text or rating), stripping unwanted characters from text, and converting the textual rating to a numeric Rating_num. The two datasets are then merged on a common identifier (restaurant name / link) to create a unified analysis-ready dataframe (df_final). Sanity checks on row counts and merge status confirm that almost all reviews find a matching restaurant record.\n",
        "\n",
        "EDA is organised using the UBM structure (Univariate, Bivariate, Multivariate).\n",
        "**Univariate analysis** examines the distribution of numeric and categorical features: overall rating distribution, cost_for_two distribution, the top 10 most-reviewed restaurants, primary cuisine counts, and the distribution of number_of_reviews per restaurant. These views reveal, for example, that ratings are generally skewed towards the higher end, a large proportion of restaurants fall into a mid-range cost segment, and a small set of restaurants account for a disproportionately high volume of reviews.\n",
        "**Bivariate analysis** then looks at how pairs of variables interact. Examples include average rating by cost bucket (Low/Medium/High), average rating by primary cuisine, rating vs. number_of_reviews (scatter), and cost_for_two vs. number_of_reviews. These charts help identify which cuisines tend to receive consistently high ratings, whether expensive restaurants are actually rated better, and how review volume relates to rating stability.\n",
        "**Multivariate analysis** combines more than two variables at a time, such as comparing rating across combinations of cuisine and cost bucket, and using correlation heatmaps and pair plots to understand relationships among numeric features (rating, cost_for_two, review counts, presence of pictures, etc.).\n",
        "\n",
        "For **hypothesis testing**, several business-relevant questions are statistically evaluated. Examples include: whether reviews with pictures receive significantly different ratings than reviews without pictures, whether higher-cost restaurants have higher average ratings than lower-cost ones, and whether there is a meaningful difference in ratings across major cuisine groups. Appropriate tests such as independent t-tests and ANOVA are used, and p-values are interpreted to accept or reject the null hypotheses.\n",
        "\n",
        "For the **machine learning** component, a binary sentiment label is derived from the numeric rating (e.g., ratings ≥ 4 as “positive”). Text preprocessing is applied to the review text: lowercasing, removal of punctuation and stopwords, tokenisation, and vectorisation using TF–IDF. Selected numeric features (such as cost_for_two and review/picture related features) can be combined with text-based features. The dataset is split into training and test sets to avoid data leakage. Multiple classification models are implemented, including **Logistic Regression** and **Random Forest** (and optionally a boosting model). Model performance is evaluated using accuracy, precision, recall, F1-score, and ROC-AUC. Cross-validation and GridSearchCV are used to tune hyperparameters, and improvements in metrics after tuning are documented.\n",
        "\n",
        "From a business perspective, the EDA provides actionable insights into which types of restaurants (cost level, cuisines, popularity) perform best and where there may be gaps or opportunities. The sentiment classification model can be used to automatically classify new reviews, flag potential service issues, and summarise customer feedback at scale.\n",
        "\n",
        "Together, the EDA and ML model form a comprehensive Zomato analytics solution that supports data-driven decisions in restaurant discovery, marketing, and quality management."
      ],
      "metadata": {
        "id": "pgK4uIus7w3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/shubhra3/Projects/tree/main/Zomato_Restaurant_EDA_ML"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zomato hosts thousands of restaurants and customer reviews, but this raw data is not directly actionable. Business teams need to understand what drives good ratings and engagement, and they also need an automatic way to interpret large volumes of textual reviews without reading each one manually.\n",
        "\n",
        "In this project, we are given two datasets:\n",
        "\n",
        "-Restaurant metadata – name, cuisines, approximate cost for two, timings, links, and collections\n",
        "\n",
        "-Customer reviews – restaurant name, reviewer details, review text, rating, metadata text, time, and picture count\n",
        "\n",
        "The goal is twofold:\n",
        "\n",
        "a) Exploratory Data Analysis (EDA)\n",
        "\n",
        "Understand the distribution of ratings, costs, cuisines, and review volumes\n",
        "\n",
        "Identify which cuisines and price segments tend to receive higher or lower ratings\n",
        "\n",
        "Analyse how review volume and pictures relate to rating patterns\n",
        "\n",
        "b) Machine Learning Classification\n",
        "\n",
        "Convert numeric ratings into a sentiment label (e.g., positive vs. non-positive)\n",
        "\n",
        "Build and evaluate classification models that predict sentiment from review text and selected restaurant attributes\n",
        "\n",
        "Use appropriate evaluation metrics (accuracy, precision, recall, F1, ROC-AUC) and apply cross-validation and hyperparameter tuning\n",
        "\n",
        "The final outcome should provide insights that help Zomato (or a similar platform) improve restaurant discovery, marketing, and quality monitoring, and a working sentiment model that can assist in automatically tagging new reviews at scale."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "notebook_start_time = time.time()\n",
        "print(\"Notebook execution started...\")\n"
      ],
      "metadata": {
        "id": "B2ler9yzS05l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from IPython.display import display\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "!pip install contractions -q\n",
        "import contractions\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load datasets directly from GitHub (raw URLs) ---\n",
        "\n",
        "meta_url = (\n",
        "    \"https://raw.githubusercontent.com/\"\n",
        "    \"shubhra3/Projects/main/\"\n",
        "    \"Zomato_Restaurant_EDA_ML/Zomato%20Restaurant%20names%20and%20Metadata.csv\"\n",
        ")\n",
        "\n",
        "reviews_url = (\n",
        "    \"https://raw.githubusercontent.com/\"\n",
        "    \"shubhra3/Projects/main/\"\n",
        "    \"Zomato_Restaurant_EDA_ML/Zomato%20Restaurant%20reviews.csv\"\n",
        ")\n",
        "\n",
        "df_meta = pd.read_csv(meta_url)\n",
        "df_reviews = pd.read_csv(reviews_url)\n",
        "\n",
        "print(\"Metadata shape:\", df_meta.shape)\n",
        "print(\"Reviews shape:\", df_reviews.shape)\n"
      ],
      "metadata": {
        "id": "sPFyxi-24DEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "display(df_meta.head())\n",
        "display(df_reviews.head())"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Metadata shape:\", df_meta.shape)\n",
        "print(\"Reviews shape:\", df_reviews.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "print(\"\\nMetadata info:\")\n",
        "df_meta.info()\n",
        "\n",
        "print(\"\\nReviews info:\")\n",
        "df_reviews.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"\\nDuplicate rows in metadata:\", df_meta.duplicated().sum())\n",
        "print(\"Duplicate rows in reviews:\", df_reviews.duplicated().sum())\n",
        "\n",
        "df_meta = df_meta.drop_duplicates().reset_index(drop=True)\n",
        "df_reviews = df_reviews.drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"\\nMissing values in metadata:\")\n",
        "print(df_meta.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in reviews:\")\n",
        "print(df_reviews.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metadata dataset has 105 restaurants and 6 columns, all stored as text (object). Most fields are complete, but Collections is missing for about half the restaurants (54 nulls) and Timings has 1 missing value. The Cost field is stored as text, so it will need cleaning and conversion to numeric (cost_for_two) for analysis.\n",
        "\n",
        "The reviews dataset is much larger, with 10,000 rows and 7 columns. Most columns are text, except Pictures, which is integer and has no missing values. There are a few missing entries in Reviewer (2), Review (9), Rating (2), Metadata (2), and Time (2). These rows need to be handled or dropped before modelling.\n",
        "\n",
        "Overall, the data shows a many-to-one relationship (many reviews per restaurant). Some key variables like ratings and cost are stored as strings, so type conversion and standardisation are essential preparation steps before EDA and machine learning."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "print(\"Metadata columns:\")\n",
        "print(df_meta.columns.tolist())\n",
        "\n",
        "print(\"\\nReviews columns:\")\n",
        "print(df_reviews.columns.tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "print(\"\\nSummary statistics for numeric columns in METADATA:\")\n",
        "display(df_meta.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for numeric columns in REVIEWS:\")\n",
        "display(df_reviews.describe())\n",
        "\n",
        "# ===============================\n",
        "# Dataset Describe (all cols)\n",
        "# ===============================\n",
        "print(\"\\nSummary for ALL columns in METADATA:\")\n",
        "display(df_meta.describe(include='all').T)\n",
        "\n",
        "print(\"\\nSummary for ALL columns in REVIEWS:\")\n",
        "display(df_reviews.describe(include='all').T)"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata Dataset (Zomato Restaurant names and Metadata)\n",
        "\n",
        "  Name – Official restaurant name on Zomato (105 unique restaurants).\n",
        "\n",
        "  Links – Zomato URL for each restaurant’s page (1:1 with Name).\n",
        "\n",
        "  Cost – Approximate cost for two people, stored as text (e.g., \"500\"), needs conversion to numeric.\n",
        "\n",
        "  Collections – Zomato collection tags (e.g., “Food Hygiene Rated Restaurants in Hyderabad”); present only for ~half of the restaurants.\n",
        "\n",
        "  Cuisines – Primary cuisines served, often a comma-separated list (e.g., “North Indian, Chinese”).\n",
        "\n",
        "  Timings – Opening and closing times or schedule text for each restaurant.\n",
        "\n",
        "Reviews Dataset (Zomato Restaurant reviews)\n",
        "\n",
        "  Restaurant – Restaurant name as used in reviews; links many reviews to a single restaurant.\n",
        "\n",
        "  Reviewer – Name/ID of the user who posted the review (highly unique, a few repeat reviewers).\n",
        "\n",
        "  Review – Free-text review content; includes short comments like “good” as well as longer feedback.\n",
        "\n",
        "  Rating – Star rating given by the reviewer (text form, values like “1” to “5”).\n",
        "\n",
        "  Metadata – Small info snippet from Zomato (e.g., “1 Review , 2 Followers”) about the reviewer.\n",
        "\n",
        "  Time – Timestamp string when the review was posted.\n",
        "\n",
        "  Pictures – Integer count of photos attached to the review (mostly 0; max observed is 64)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "def show_unique_counts(df, df_name):\n",
        "    print(f\"\\n========== Unique value counts in {df_name} ==========\")\n",
        "    display(df.nunique().to_frame(name=\"unique_count\"))\n",
        "\n",
        "    # (Optional) show actual unique values for low-cardinality columns\n",
        "    print(f\"\\nColumns in {df_name} with <= 10 unique values (showing actual values):\")\n",
        "    for col in df.columns:\n",
        "        uniq_vals = df[col].dropna().unique()\n",
        "        if len(uniq_vals) <= 10:\n",
        "            print(f\"\\nColumn: {col}  |  Unique values ({len(uniq_vals)}):\")\n",
        "            print(uniq_vals)\n",
        "\n",
        "show_unique_counts(df_meta, \"METADATA\")\n",
        "show_unique_counts(df_reviews, \"REVIEWS\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal: clean both datasets and create a unified, analysis-ready dataframe.\n",
        "\n",
        "# Work on copies to keep raw data intact\n",
        "meta = df_meta.copy()\n",
        "reviews = df_reviews.copy()\n",
        "\n",
        "# 1. Strip leading/trailing spaces from all string columns\n",
        "for col in meta.select_dtypes(include='object').columns:\n",
        "    meta[col] = meta[col].str.strip()\n",
        "\n",
        "for col in reviews.select_dtypes(include='object').columns:\n",
        "    reviews[col] = reviews[col].str.strip()\n",
        "\n",
        "# 2. Standardize restaurant name keys in both datasets for reliable merge\n",
        "meta[\"restaurant_key\"] = meta[\"Name\"].str.lower()\n",
        "reviews[\"restaurant_key\"] = reviews[\"Restaurant\"].str.lower()\n",
        "\n",
        "# 3. Clean Cost field -> numeric \"cost_for_two\"\n",
        "def clean_cost(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    # remove commas and keep digits only (works for formats like \"₹1,200 for two\")\n",
        "    s = str(x).replace(\",\", \"\")\n",
        "    nums = re.findall(r\"\\d+\", s)\n",
        "    if not nums:\n",
        "        return np.nan\n",
        "    return float(nums[0])\n",
        "\n",
        "meta[\"cost_for_two\"] = meta[\"Cost\"].apply(clean_cost)\n",
        "\n",
        "# 4. Handle missing Collections and Timings\n",
        "meta[\"Collections\"] = meta[\"Collections\"].fillna(\"No collection tagged\")\n",
        "meta[\"Timings\"] = meta[\"Timings\"].fillna(\"Not available\")\n",
        "\n",
        "# 5. Clean Rating in reviews -> numeric Rating_num\n",
        "def parse_rating(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    # works for \"4.2\", \"Rated 4.2\", etc.\n",
        "    match = re.search(r\"(\\d+(\\.\\d+)?)\", str(x))\n",
        "    return float(match.group(1)) if match else np.nan\n",
        "\n",
        "reviews[\"Rating_num\"] = reviews[\"Rating\"].apply(parse_rating)\n",
        "\n",
        "# 6. Handle missing reviewer names and unusable rows\n",
        "reviews[\"Reviewer\"] = reviews[\"Reviewer\"].fillna(\"Anonymous\")\n",
        "\n",
        "# Drop rows where BOTH review text and rating are missing\n",
        "reviews = reviews.dropna(subset=[\"Review\", \"Rating\"], how=\"all\").reset_index(drop=True)\n",
        "\n",
        "# 7. Parse review time (if possible)\n",
        "reviews[\"Time_parsed\"] = pd.to_datetime(reviews[\"Time\"], errors=\"coerce\")\n",
        "\n",
        "# 8. Merge reviews with metadata on standardized restaurant key\n",
        "df_merged = reviews.merge(\n",
        "    meta,\n",
        "    on=\"restaurant_key\",\n",
        "    how=\"left\",\n",
        "    indicator=True\n",
        ")\n",
        "\n",
        "# 9. Basic sanity check for merge quality\n",
        "print(\"\\nMerge status (how many reviews matched metadata):\")\n",
        "print(df_merged[\"_merge\"].value_counts())\n",
        "\n",
        "# Drop helper columns not needed for analysis\n",
        "df_merged.drop(columns=[\"_merge\"], inplace=True)\n",
        "\n",
        "# Optional: tidy final set of columns for analysis\n",
        "df_final = df_merged[\n",
        "    [\n",
        "        \"Restaurant\",      # from reviews\n",
        "        \"Name\",            # official name from metadata\n",
        "        \"Cuisines\",\n",
        "        \"cost_for_two\",\n",
        "        \"Timings\",\n",
        "        \"Reviewer\",\n",
        "        \"Review\",\n",
        "        \"Rating\",\n",
        "        \"Rating_num\",\n",
        "        \"Metadata\",\n",
        "        \"Time\",\n",
        "        \"Time_parsed\",\n",
        "        \"Pictures\",\n",
        "        \"Links\",\n",
        "        \"Collections\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "print(\"\\nFinal analysis-ready dataframe (top 5 rows):\")\n",
        "df_final.head()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Manipulations done:**\n",
        "\n",
        "a) Cleaned all text columns by removing extra spaces and standardising\n",
        "restaurant names to lowercase (restaurant_key) so that metadata and reviews can be merged reliably.\n",
        "\n",
        "b) Parsed the Cost column into a numeric cost_for_two feature by extracting only the digits from strings like “₹1,200 for two”.\n",
        "\n",
        "c) Handled missing values in Collections and Timings by replacing them with meaningful labels (“No collection tagged”, “Not available”).\n",
        "\n",
        "d) Converted textual Rating into a numeric Rating_num feature using regex, and treated rows with both missing rating and review text as unusable and dropped them.\n",
        "\n",
        "e) Normalised reviewer names by filling missing values with “Anonymous” and parsed the Time column into a proper datetime field (Time_parsed).\n",
        "\n",
        "f) Merged the reviews and metadata datasets on the standardised restaurant key to create a single analysis-ready dataframe (df_final) that contains both restaurant attributes and review-level information.\n",
        "\n",
        "**Initial insights:**\n",
        "\n",
        "a) The metadata file covers a limited set of restaurants (105), but there is a much larger volume of reviews, giving enough data for meaningful EDA.\n",
        "\n",
        "b) Only a relatively small portion of rows required dropping (where both rating and review were missing), so most of the information could be retained.\n",
        "\n",
        "c) Cost and rating fields originally stored as text needed cleaning before any statistical analysis; after transformation, they can now be used for visualisations, correlations, and modelling.\n",
        "\n",
        "d) With the unified df_final table, we can now analyse how cuisines, cost, and timings relate to ratings, review volume, and user engagement (pictures), and build charts following the U–B–M structure."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate(U) - Chart 1 to Chart 5\n",
        "# Chart 1: Distribution of restaurant ratings\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df_final['Rating'].dropna(), bins=20, kde=True)\n",
        "plt.title(\"Distribution of Restaurant Ratings\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram is the simplest way to see how ratings are distributed and whether they are skewed towards high or low values.”"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most ratings are clustered between 3.5 and 4.5, indicating generally positive feedback. Very low ratings are relatively rare."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This suggests Zomato’s listed restaurants maintain decent quality, so highlighting the few truly exceptional restaurants (4.5+) could drive positive business impact. A lack of very low ratings also reduces reputational risk."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 2 – Distribution of cost_for_two (Histogram)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(\n",
        "    df_final[\"cost_for_two\"].dropna(),\n",
        "    bins=15,\n",
        "    kde=True\n",
        ")\n",
        "plt.title(\"Distribution of Cost for Two\")\n",
        "plt.xlabel(\"Cost for Two\")\n",
        "plt.ylabel(\"Number of Restaurants\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a histogram because it clearly shows how “cost_for_two” is distributed across restaurants. It helps me see whether prices are concentrated in a particular range, whether the distribution is skewed, and if there are any outliers in the very low or very high price bands."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram shows that most restaurants fall into the lower–to–mid price range, with fewer restaurants at very high “cost_for_two” values. This indicates a right-skewed distribution: the market is dominated by budget and mid-range options, while premium restaurants are relatively rare."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights are useful for business decisions. Knowing that most restaurants are clustered in a specific price band helps platforms or owners design targeted campaigns—for example, deals and bundles for the dominant price segment, and special positioning for premium restaurants.\n",
        "\n",
        "A potential negative insight is that if the market is overcrowded in the same low–mid price range, new entrants with similar pricing may struggle to stand out, leading to slower growth. In such a case, businesses may need to differentiate either by slightly repositioning price or by offering unique cuisines, ambience, or promotions."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 Top 10 most-reviewed restaurants\n",
        "\n",
        "# Number of reviews per restaurant\n",
        "reviews_per_restaurant = (\n",
        "    df_final\n",
        "    .groupby('Restaurant')\n",
        "    .size()\n",
        "    .reset_index(name='review_count')\n",
        ")\n",
        "\n",
        "top10_reviews = (\n",
        "    reviews_per_restaurant\n",
        "    .sort_values('review_count', ascending=False)\n",
        "    .head(10)\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='Restaurant', y='review_count', data=top10_reviews)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Restaurant')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.title('Top 10 Most-Reviewed Restaurants')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar chart because it is the clearest way to compare review counts across a small number of categories. For the top 10 restaurants, a bar chart makes it easy to see which places receive the highest engagement and how big the gap is between them."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that a few restaurants clearly dominate in terms of review volume, acting as “star performers” on the platform. Some restaurants have significantly more reviews than others, indicating higher visibility, stronger customer recall, or better marketing and word-of-mouth.\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top restaurants can be targeted for premium partnerships, featured listings, or flagship campaigns.\n",
        "\n",
        "Restaurants just below the top tier can be nudged with promotions to push them into higher visibility.\n",
        "\n",
        "On the negative side, over-concentration of reviews on a few outlets may mean many other restaurants remain undiscovered. If not addressed, this can limit overall ecosystem growth. The platform can design campaigns to distribute traffic more evenly and support emerging restaurants."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 4 – Count of primary cuisine types\n",
        "\n",
        "# Create a primary_cuisine column (first cuisine in the list)\n",
        "df_final[\"primary_cuisine\"] = df_final[\"Cuisines\"].apply(\n",
        "    lambda x: str(x).split(\",\")[0].strip() if pd.notna(x) else \"Unknown\"\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "cuisine_counts = df_final[\"primary_cuisine\"].value_counts().head(15)  # top 15 cuisines\n",
        "sns.barplot(x=cuisine_counts.index, y=cuisine_counts.values)\n",
        "plt.title(\"Count of Restaurants by Primary Cuisine (Top 15)\")\n",
        "plt.xlabel(\"Primary Cuisine\")\n",
        "plt.ylabel(\"Number of Restaurants\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I choose a bar chart because it is the most intuitive way to compare frequencies of different cuisine types. Since “cuisine” is a categorical variable, a bar chart clearly shows which cuisines appear most often and which are relatively rare in the dataset."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that a few cuisines (for example, North Indian, Chinese, and Fast Food) dominate the restaurant landscape, while others (such as Continental or niche regional cuisines) appear much less frequently. This indicates that the platform’s supply is skewed towards a small set of popular cuisines."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive impact:**\n",
        "\n",
        "a) Marketing can highlight the most popular cuisines in city-specific campaigns.\n",
        "\n",
        "b) The platform can design filters and collections around the top cuisines to improve user discovery and engagement.\n",
        "\n",
        "**Potential negative aspect:**\n",
        "\n",
        "a) Over-representation of a few cuisines may lead to menu fatigue for users and reduced differentiation for restaurants.\n",
        "\n",
        "b) Under-represented cuisines might indicate missed opportunities in niche markets.\n",
        "\n",
        "Addressing this imbalance (e.g., by promoting diverse or emerging cuisines) can improve customer satisfaction and support long-term growth."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 5 – Distribution of number_of_reviews per restaurant\n",
        "\n",
        "# Compute review count per restaurant\n",
        "reviews_per_restaurant = (\n",
        "    df_final.groupby(\"Restaurant\")[\"Review\"]\n",
        "    .count()\n",
        "    .reset_index(name=\"number_of_reviews\")\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(\n",
        "    reviews_per_restaurant[\"number_of_reviews\"],\n",
        "    bins=20,\n",
        "    kde=True\n",
        ")\n",
        "plt.title(\"Distribution of Number of Reviews per Restaurant\")\n",
        "plt.xlabel(\"Number of Reviews\")\n",
        "plt.ylabel(\"Number of Restaurants\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose this chart to understand how customer attention is distributed across restaurants. The number of reviews is a simple but powerful proxy for popularity and engagement. Looking at its distribution helps us see whether most restaurants get a steady flow of feedback or whether a small set of places dominate the conversation.\n",
        "\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows a highly right-skewed distribution: most restaurants have only a small number of reviews, while a few have a very large number. This suggests a “winner-takes-more” pattern where a small group of restaurants attract the bulk of customer interactions. It may also indicate that many restaurants are relatively new, less visible, or not actively promoted."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights are useful for business decisions.\n",
        "\n",
        "**Positive impact:**\n",
        "\n",
        "a) Highly reviewed restaurants can be treated as “hero” properties for campaigns, featured lists, or premium partnerships.\n",
        "\n",
        "b) Low-review restaurants can be targeted for onboarding support, review-generation campaigns, or discounts to stimulate engagement.\n",
        "\n",
        "**Potential negative signals:**\n",
        "\n",
        "a) A very large tail of restaurants with almost no reviews may indicate poor discoverability or low customer trust.\n",
        "\n",
        "b) If not addressed, these restaurants may churn from the platform or fail to grow, which can limit overall marketplace depth.\n",
        "\n",
        "By acting on both ends of this distribution, the platform can improve user experience and restaurant retention at the same time."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bivariate(B) - Chart 6 to Chart 10\n",
        "# Chart - 6 Average Rating by Cost Bucket\n",
        "\n",
        "rest_agg = (df_final.groupby('Restaurant')\n",
        "            .agg(\n",
        "                avg_rating=('Rating_num', 'mean'),\n",
        "                cost_for_two=('cost_for_two', 'mean'),\n",
        "                cuisines=('Cuisines', 'first'),\n",
        "                num_reviews=('Rating_num', 'size')\n",
        "            ).reset_index())\n",
        "\n",
        "rest_agg['Primary_cuisine'] = rest_agg['cuisines'].str.split(',').str[0].str.strip()\n",
        "\n",
        "# Create cost buckets\n",
        "rest_agg['cost_bucket'] = pd.cut(\n",
        "    rest_agg['cost_for_two'],\n",
        "    bins=[0, 300, 800, rest_agg['cost_for_two'].max()],\n",
        "    labels=['Low', 'Medium', 'High'],\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# Compute mean rating per bucket\n",
        "cost_rating = (rest_agg\n",
        "               .groupby('cost_bucket', observed=False)['avg_rating']\n",
        "               .mean()\n",
        "               .reset_index())\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(data=cost_rating, x='cost_bucket', y='avg_rating')\n",
        "plt.title('Average Rating by Cost Bucket')\n",
        "plt.xlabel('Cost for Two (Bucket)')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar chart because it clearly compares average ratings across a few discrete spending categories. It’s an easy way to see whether cheaper, mid-range, or premium restaurants tend to receive better feedback from diners."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that (describe from your output, e.g. “medium-priced restaurants have the highest average rating, while low-cost and high-cost places are slightly lower”). This suggests that customers may perceive better value or more consistent experience in the mid-price band."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Platforms and restaurant partners can focus on the strongest-performing cost segment and study what those restaurants do well (portion size, ambience, service) to replicate across others. If a particular bucket shows weaker ratings, it signals a risk of negative reviews and churn, prompting targeted improvements or promotions."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 Mean rating per primary cuisine\n",
        "\n",
        "cuisine_rating = (rest_agg\n",
        "                  .groupby('Primary_cuisine')['avg_rating']\n",
        "                  .mean()\n",
        "                  .reset_index()\n",
        "                  .sort_values('avg_rating', ascending=False)\n",
        "                  .head(10))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=cuisine_rating, x='avg_rating', y='Primary_cuisine')\n",
        "plt.title('Top 10 Cuisines by Average Rating')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Primary Cuisine')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A horizontal bar chart works well for comparing many categories like cuisines. It keeps labels readable and allows quick comparison of which cuisine types are rated higher or lower.\n",
        "\n"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart highlights that cuisines such as (fill in from your results, e.g. “Italian and Continental”) tend to have higher average ratings, whereas (e.g. “Fast Food or Café”) are rated relatively lower. This hints at customer preferences and perceived quality differences across cuisine types."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason. Yes. High-rating cuisines can be promoted more in recommendations, collections, or campaigns. Lower-rating cuisines indicate potential quality issues or expectation gaps; platforms can work with those restaurants on menu optimisation, service, or positioning to avoid reputation damage and negative growth."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 Flag for pictures at review level\n",
        "df_final['has_pictures'] = df_final['Pictures'] > 0\n",
        "\n",
        "pic_rating = (df_final\n",
        "              .groupby('has_pictures')['Rating_num']\n",
        "              .mean()\n",
        "              .reset_index())\n",
        "\n",
        "# Make labels nicer\n",
        "pic_rating['has_pictures_label'] = pic_rating['has_pictures'].map(\n",
        "    {True: 'With Pictures', False: 'No Pictures'}\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(data=pic_rating, x='has_pictures_label', y='Rating_num')\n",
        "plt.title('Average Rating: Reviews With vs Without Pictures')\n",
        "plt.xlabel('Review Type')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a simple bar chart to compare just two groups: reviews with photos and reviews without photos. This makes it easy to see if visual content is associated with different rating behaviour."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that reviews with pictures have (slightly / noticeably) [higher or lower – adjust to your result] average ratings than those without pictures. This suggests that users who take effort to upload photos may be more engaged and possibly more satisfied (or more critical, depending on the direction)."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Yes. If photo reviews correlate with higher ratings, the platform can encourage users to upload pictures, which improves both content richness and overall perception. If photo reviews are harsher, they are an early-warning signal for quality problems and help identify restaurants at risk of negative word-of-mouth."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 Average rating vs number_of_reviews per restaurant (scatter)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(data=rest_agg, x='num_reviews', y='avg_rating', alpha=0.6)\n",
        "plt.title('Average Rating vs Number of Reviews per Restaurant')\n",
        "plt.xlabel('Number of Reviews')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot is ideal for seeing the relationship between two numeric variables — here, popularity (number of reviews) and satisfaction (average rating). It lets us visually detect clusters and trends rather than just a single summary number.\n",
        "\n"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The points show that most restaurants cluster around (e.g. “moderate review counts and mid-to-high ratings”). A few restaurants have very high review volumes; their ratings indicate whether “popular” also means “well-liked” or whether popularity sometimes comes with mixed feedback."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Yes. Highly reviewed restaurants with strong ratings can be marked as “hero” listings for promotions. Restaurants with many reviews but mediocre ratings may be at risk — the platform can flag them for quality interventions so that high visibility doesn’t turn into negative growth through poor experiences."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 Cost_for_two vs number_of_reviews (scatter)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(data=rest_agg, x='cost_for_two', y='num_reviews', alpha=0.6)\n",
        "plt.title('Cost for Two vs Number of Reviews')\n",
        "plt.xlabel('Cost for Two')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, a scatter plot is appropriate to understand how pricing (cost_for_two) relates to demand or engagement (number_of_reviews). It gives a visual sense of whether customers prefer budget, mid-range, or premium options."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates that (describe pattern, e.g. “most highly reviewed restaurants are in the mid-price band, with fewer very expensive places attracting large numbers of reviews”). This suggests that customers interact more with restaurants that offer a balance between affordability and experience."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Understanding which price bands drive engagement helps in positioning, discount strategy, and featured listings. If very high-priced restaurants show low review counts, they may need targeted campaigns or differentiated messaging to avoid being overlooked, which could otherwise hurt their revenue growth."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariate(M) - Chart 11 to Chart 15\n",
        "# One-time prep (run once before the multivariate charts)#\n",
        "# 1) Aggregate to restaurant level\n",
        "df_restaurant_stats = (\n",
        "    df_final\n",
        "    .groupby('Name')\n",
        "    .agg(\n",
        "        avg_rating=('Rating_num', 'mean'),\n",
        "        number_of_reviews=('Review', 'count'),\n",
        "        avg_cost_for_two=('cost_for_two', 'mean'),\n",
        "        total_pictures=('Pictures', 'sum'),\n",
        "        # take primary cuisine as the first cuisine in the list\n",
        "        primary_cuisine=('Cuisines', lambda x: x.iloc[0].split(',')[0].strip())\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# 2) Create cost bucket (Low / Medium / High)\n",
        "bins = [0, 400, 800, df_restaurant_stats['avg_cost_for_two'].max()]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df_restaurant_stats['cost_bucket'] = pd.cut(\n",
        "    df_restaurant_stats['avg_cost_for_two'],\n",
        "    bins=bins,\n",
        "    labels=labels,\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# 3) Flag for presence of pictures\n",
        "df_restaurant_stats['has_pictures'] = np.where(\n",
        "    df_restaurant_stats['total_pictures'] > 0,\n",
        "    'With pictures',\n",
        "    'No pictures'\n",
        ")\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 11 – Heatmap of average rating by primary cuisine and cost bucket\n",
        "# Limit to top 8 cuisines to keep the heatmap readable\n",
        "top_cuisines = df_restaurant_stats['primary_cuisine'].value_counts().nlargest(8).index\n",
        "df_heat = df_restaurant_stats[df_restaurant_stats['primary_cuisine'].isin(top_cuisines)]\n",
        "\n",
        "pivot_cuisine_cost = df_heat.pivot_table(\n",
        "    index='primary_cuisine',\n",
        "    columns='cost_bucket',\n",
        "    values='avg_rating',\n",
        "    aggfunc='mean'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(pivot_cuisine_cost, annot=True, fmt=\".2f\")\n",
        "plt.title(\"Average Rating by Primary Cuisine and Cost Bucket\")\n",
        "plt.xlabel(\"Cost Bucket\")\n",
        "plt.ylabel(\"Primary Cuisine\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_3ZuOqxPa6u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a heatmap because it shows how two categorical variables (cuisine and cost bucket) jointly influence a numeric outcome (average rating). It lets us quickly spot combinations that perform better or worse."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart highlights which cuisine–price combinations perform best. For example, we may see that mid-priced [fill from your result] cuisines have the strongest average ratings, while some low-cost or high-cost combinations lag behind."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. High-performing cuisine–price pairs can be prioritized in recommendations and campaigns. Weak combinations reveal where customer expectations are not being met, so those segments can be targeted for menu, pricing, or experience improvements to avoid negative reviews and revenue loss."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 12 – Boxplot of rating by cost bucket with picture flag (multivariate)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(\n",
        "    data=df_restaurant_stats,\n",
        "    x='cost_bucket',\n",
        "    y='avg_rating',\n",
        "    hue='has_pictures'\n",
        ")\n",
        "plt.title(\"Distribution of Average Rating by Cost Bucket and Picture Presence\")\n",
        "plt.xlabel(\"Cost Bucket\")\n",
        "plt.ylabel(\"Average Rating\")\n",
        "plt.legend(title=\"Pictures\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot is ideal for comparing rating distributions across groups. Adding the has_pictures flag as a hue turns it into a multivariate view, showing how ratings vary by both price level and presence of photos."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see both the median rating and spread for each cost bucket, and whether restaurants with pictures tend to have slightly higher or lower ratings than those without, within the same price band."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. If restaurants with photos consistently show better ratings within each cost bucket, the platform can nudge other restaurants to add photos. If any segment (e.g. low-cost with no pictures) has systematically lower ratings, it becomes a clear target for quality and content improvements."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 13 – Scatter: avg cost vs number_of_reviews with cuisine & rating (true multivariate)\n",
        "# Focus on top 5 cuisines to keep the plot readable\n",
        "top5_cuisines = df_restaurant_stats['primary_cuisine'].value_counts().nlargest(5).index\n",
        "df_scatter = df_restaurant_stats[df_restaurant_stats['primary_cuisine'].isin(top5_cuisines)]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(\n",
        "    data=df_scatter,\n",
        "    x='avg_cost_for_two',\n",
        "    y='number_of_reviews',\n",
        "    hue='primary_cuisine',\n",
        "    size='avg_rating',\n",
        "    sizes=(40, 200),\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title(\"Avg Cost for Two vs Number of Reviews\\n(Colored by Cuisine, Sized by Rating)\")\n",
        "plt.xlabel(\"Average Cost for Two\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scatter plot captures four aspects at once: price, popularity (reviews), cuisine (color), and perceived quality (point size). It’s a compact way to understand how pricing and cuisine interact with demand and satisfaction."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see which cuisines dominate in certain price ranges and which restaurant clusters combine high review counts with strong ratings. It may reveal, for example, that mid-priced restaurants of some cuisines attract more reviews than very premium ones."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. High-review, high-rating clusters can be tagged as “hero” restaurants. Segments with low reviews or smaller rating bubbles show where awareness or satisfaction is weaker, guiding targeted campaigns, discounts, or onboarding of better-performing options."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 14 – Correlation heatmap of numeric features\n",
        "numeric_cols = ['avg_rating', 'number_of_reviews', 'avg_cost_for_two', 'total_pictures']\n",
        "corr = df_restaurant_stats[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation Heatmap of Numeric Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A correlation heatmap summarizes relationships between all numeric variables in one view. It’s a standard multivariate diagnostic to see which variables move together and which are largely independent."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows whether, for example, number_of_reviews is positively linked with total_pictures, or whether avg_cost_for_two has any meaningful correlation with avg_rating. Many weak correlations suggest that different factors independently influence restaurant performance."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Will the gained insights help creating a positive business impact?\n"
      ],
      "metadata": {
        "id": "jYfyBkNTdE8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Strong correlations highlight levers that can be used together in business strategy (e.g., more pictures → more reviews). Weak or negative correlations may warn that simply increasing price doesn’t guarantee better ratings, so value perception must be managed carefully.\n",
        "\n"
      ],
      "metadata": {
        "id": "IPckfN3HdKsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 15 – Pairplot of numeric features with cost bucket\n",
        "plot_cols = ['avg_rating', 'number_of_reviews', 'avg_cost_for_two', 'total_pictures', 'cost_bucket']\n",
        "\n",
        "sns.pairplot(\n",
        "    df_restaurant_stats[plot_cols],\n",
        "    hue='cost_bucket',\n",
        "    diag_kind='hist'\n",
        ")\n",
        "plt.suptitle(\"Pairplot of Restaurant Metrics Colored by Cost Bucket\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pairplot gives a grid of all pairwise relationships between numeric variables, while coloring points by cost bucket. It’s a compact multivariate exploration tool, revealing patterns that might be missed in single scatter plots."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visually inspect how low-, medium-, and high-cost restaurants are distributed across reviews, pictures, and ratings. For example, medium-cost restaurants might cluster at moderate price but span a wide range of review counts."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "G2vcUPMWdncq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. This view helps identify which cost segment dominates in the most attractive region of the feature space (good ratings + healthy review volume). It also shows if any price segment is underperforming consistently, signalling where product, pricing, or marketing adjustments are required."
      ],
      "metadata": {
        "id": "xliYWcz3dvWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the visualizations, I defined three hypotheses:\n",
        "\n",
        "1. Restaurants reviews with photos differ with restaurant reviews without photos.\n",
        "\n",
        "2. Average ratings differ across price segments (Low, Medium, High cost for two).\n",
        "\n",
        "3. Restaurants with higher average cost for two receive more reviews.\n",
        "\n",
        "There is a linear relationship between average cost for two and number of reviews a restaurant receives.\n",
        "I then performed appropriate statistical tests (t-test, ANOVA, Pearson correlation) to validate these patterns quantitatively."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants reviews with photos differ with restaurant reviews without photos\n",
        "\n",
        "Null and alternate hypothesis\n",
        "\n",
        "Null hypothesis (H₀): The mean rating of reviews with pictures is equal to the mean rating of reviews without pictures.\n",
        "\n",
        "Alternate hypothesis (H₁): The mean rating of reviews with pictures is higher than the mean rating of reviews without pictures."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "with_pics_reviews = df_final[df_final['Pictures'] > 0]['Rating_num'].dropna()\n",
        "no_pics_reviews   = df_final[df_final['Pictures'] == 0]['Rating_num'].dropna()\n",
        "\n",
        "print(\"Sample sizes (reviews):\", len(with_pics_reviews), \"with pictures,\", len(no_pics_reviews), \"no pictures\")\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(\n",
        "    with_pics_reviews,\n",
        "    no_pics_reviews,\n",
        "    equal_var=False  # Welch’s t-test\n",
        ")\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample independent t-test (Welch’s t-test) to compare the mean ratings of two independent groups: reviews with pictures and reviews without pictures."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dependent variable (rating) is continuous, and the two groups are independent. Sample sizes and variances may be different, so Welch’s t-test is appropriate because it does not assume equal variances between groups."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion based on the result**\n",
        "\n",
        "The p-value is approximately 1.09 × 10⁻²⁷, which is far below 0.05. Therefore, I reject the null hypothesis and conclude that there is a statistically significant difference in mean ratings. Reviews with pictures have higher average ratings than reviews without pictures.\n",
        "Business-wise, this suggests that encouraging customers to upload photos with their reviews may be associated with better perceived experience and higher ratings, which can positively impact restaurant discovery and marketing strategies."
      ],
      "metadata": {
        "id": "_-eTuTIH1ezV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average ratings differ across price segments (Low, Medium, High cost for two).\n",
        "Null and Alternate hypothesis\n",
        "\n",
        "Null hypothesis (H₀): The mean average rating is the same for all three cost buckets (Low, Medium, High).\n",
        "\n",
        "Alternate hypothesis (H₁): At least one cost bucket has a different mean average rating compared to the others"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Drop rows without cost_bucket\n",
        "df_cost = df_restaurant_stats.dropna(subset=['cost_bucket'])\n",
        "\n",
        "low_ratings    = df_cost[df_cost['cost_bucket'] == 'Low']['avg_rating'].dropna()\n",
        "medium_ratings = df_cost[df_cost['cost_bucket'] == 'Medium']['avg_rating'].dropna()\n",
        "high_ratings   = df_cost[df_cost['cost_bucket'] == 'High']['avg_rating'].dropna()\n",
        "\n",
        "print(\"Sample sizes:\",\n",
        "      len(low_ratings), \"Low,\",\n",
        "      len(medium_ratings), \"Medium,\",\n",
        "      len(high_ratings), \"High\")\n",
        "\n",
        "# One-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(low_ratings, medium_ratings, high_ratings)\n",
        "\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a one-way ANOVA (Analysis of Variance) on average ratings across the three cost buckets."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA is appropriate when comparing the means of a continuous variable (average rating) across more than two independent groups (Low, Medium, High cost). It tests whether at least one group mean differs significantly."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        " p-value < 0.05 → reject H₀ so cost segment affects ratings."
      ],
      "metadata": {
        "id": "3mWo7X-i2CsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants with higher average cost for two receive more reviews.\n",
        "\n",
        "Null and alternate hypothesis\n",
        "\n",
        "Null hypothesis (H₀): There is no linear relationship between average cost for two and number of reviews. The true Pearson correlation is zero.\n",
        "\n",
        "Alternate hypothesis (H₁): There is a linear relationship between average cost for two and number of reviews (correlation ≠ 0).Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Drop missing values\n",
        "df_corr = df_restaurant_stats.dropna(subset=['avg_cost_for_two', 'number_of_reviews'])\n",
        "\n",
        "x = df_corr['avg_cost_for_two']\n",
        "y = df_corr['number_of_reviews']\n",
        "\n",
        "# Pearson correlation\n",
        "r_value, p_value = stats.pearsonr(x, y)\n",
        "\n",
        "print(\"Correlation coefficient (r):\", r_value)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Pearson correlation test between avg_cost_for_two and number_of_reviews."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both variables are continuous numeric features, and I want to test for a linear relationship between them. Pearson correlation gives both the strength and direction of the linear relationship and a p-value for statistical significance."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "\n",
        "|r| is small and p-value ≥ 0.05 → there is no strong evidence of a linear relationship."
      ],
      "metadata": {
        "id": "za50WJ-03YB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Work on a copy so original df_final stays intact\n",
        "df_model = df_final.copy()\n",
        "\n",
        "# Check missing values\n",
        "print(\"Missing values before imputation:\\n\")\n",
        "print(df_model.isnull().sum())\n",
        "\n",
        "# Drop rows with missing target (Rating_num) - cannot train model without target\n",
        "df_model = df_model[~df_model['Rating_num'].isna()]\n",
        "\n",
        "# Impute numeric column: cost_for_two with median (robust to outliers)\n",
        "df_model['cost_for_two'] = df_model['cost_for_two'].fillna(df_model['cost_for_two'].median())\n",
        "\n",
        "# Fill text-like columns with 'Unknown' when missing\n",
        "for col in ['Timings', 'Collections', 'Reviewer', 'Review', 'Metadata']:\n",
        "    df_model[col] = df_model[col].fillna('Unknown')\n",
        "\n",
        "print(\"\\nMissing values AFTER imputation:\\n\")\n",
        "print(df_model.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Rating_num, I dropped rows with missing values because this is the target and cannot be reliably imputed.\n",
        "\n",
        "For cost_for_two, I used median imputation, which is robust to outliers and preserves the central tendency.\n",
        "\n",
        "For text fields like Timings, Collections, Reviewer, Review, Metadata, I filled with \"Unknown\" to keep those rows while explicitly marking missing information."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Outlier handling on cost_for_two using IQR-based clipping\n",
        "\n",
        "q1 = df_model['cost_for_two'].quantile(0.25)\n",
        "q3 = df_model['cost_for_two'].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "print(\"cost_for_two - Q1:\", q1, \"Q3:\", q3, \"IQR:\", iqr)\n",
        "print(\"Lower bound:\", lower_bound, \"Upper bound:\", upper_bound)\n",
        "\n",
        "# Create a clipped version (keep original for reference)\n",
        "df_model['cost_for_two_clipped'] = df_model['cost_for_two'].clip(lower_bound, upper_bound)\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used IQR-based clipping on cost_for_two to cap extreme low/high values. This keeps all rows but reduces the influence of extreme outliers on models and statistics."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical Encoding\n",
        "\n",
        "# Primary cuisine (first item in the Cuisines list)\n",
        "df_model['primary_cuisine'] = df_model['Cuisines'].str.split(',').str[0].str.strip()\n",
        "\n",
        "# Cost bucket based on clipped cost_for_two\n",
        "bins = [0, 500, 1500, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df_model['cost_bucket'] = pd.cut(\n",
        "    df_model['cost_for_two_clipped'],\n",
        "    bins=bins,\n",
        "    labels=labels,\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# Pictures flag (0/1)\n",
        "df_model['has_pictures'] = (df_model['Pictures'] > 0).astype(int)\n",
        "\n",
        "# One-Hot Encode selected low-cardinality categorical features\n",
        "cat_cols = ['primary_cuisine', 'cost_bucket']\n",
        "df_cats = pd.get_dummies(df_model[cat_cols], drop_first=True)\n",
        "\n",
        "df_cats.head()"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used one-hot encoding (via get_dummies) for primary_cuisine and cost_bucket. These features have manageable cardinality, and one-hot encoding works well for tree-based and linear models without imposing an ordinal relationship where none exists."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "\n",
        "# First, set up basics:\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Work on a clean text column\n",
        "df_model['review_text'] = df_model['Review'].astype(str)\n",
        "\n",
        "# Expand Contraction\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "df_model['review_text'] = df_model['review_text'].apply(expand_contractions)"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df_model['review_text'] = df_model['review_text'].str.lower()"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "def remove_punct(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df_model['review_text'] = df_model['review_text'].apply(remove_punct)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "def remove_urls_and_digit_words(text):\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    words = [w for w in text.split() if not any(ch.isdigit() for ch in w)]\n",
        "    return \" \".join(words)\n",
        "\n",
        "df_model['review_text'] = df_model['review_text'].apply(remove_urls_and_digit_words)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "def remove_stopwords(text):\n",
        "    words = [w for w in text.split() if w not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "df_model['review_text'] = df_model['review_text'].apply(remove_stopwords)\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "df_model['review_text'] = df_model['review_text'].str.strip()"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "def simple_rephrase(text):\n",
        "    text = text.replace('very very', 'very')\n",
        "    return text\n",
        "\n",
        "df_model['review_text'] = df_model['review_text'].apply(simple_rephrase)"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt_tab')\n",
        "df_model['review_tokens'] = df_model['review_text'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (Lemmatization)\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(t) for t in tokens]\n",
        "\n",
        "df_model['review_tokens_lemmatized'] = df_model['review_tokens'].apply(lemmatize_tokens)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used lemmatization, which reduces words to their base form (e.g., “running” → “run”) while keeping valid dictionary forms. This reduces vocabulary size and noise, which is useful for text models."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "df_model['review_pos'] = df_model['review_tokens_lemmatized'].apply(nltk.pos_tag)"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Join tokens back into cleaned strings\n",
        "df_model['review_clean_final'] = df_model['review_tokens_lemmatized'].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "X_text = tfidf.fit_transform(df_model['review_clean_final'])\n",
        "\n",
        "X_text.shape  # (n_samples, 1000)"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used TF-IDF vectorization, which gives higher weight to important terms that are frequent in a review but not common across all reviews. This is better than simple counts when we care about discriminative words."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Basic text-based numeric features\n",
        "df_model['review_char_len'] = df_model['Review'].astype(str).str.len()\n",
        "df_model['review_word_count'] = df_model['Review'].astype(str).str.split().apply(len)\n",
        "\n",
        "# Time-based features\n",
        "df_model['review_hour'] = df_model['Time_parsed'].dt.hour\n",
        "df_model['is_weekend'] = df_model['Time_parsed'].dt.dayofweek.isin([5, 6]).astype(int)\n",
        "\n",
        "# We already have:\n",
        "# - cost_for_two_clipped\n",
        "# - has_pictures\n",
        "# - cost_bucket, primary_cuisine"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection(simple statistics)\n",
        "\n",
        "# Numeric features for correlation with Rating_num\n",
        "num_cols = [\n",
        "    'Rating_num',\n",
        "    'cost_for_two_clipped',\n",
        "    'Pictures',\n",
        "    'review_char_len',\n",
        "    'review_word_count',\n",
        "    'review_hour'\n",
        "]\n",
        "\n",
        "corr_mat = df_model[num_cols].corr()\n",
        "print(\"Correlation of numeric features with Rating_num:\\n\")\n",
        "print(corr_mat['Rating_num'].sort_values(ascending=False))\n",
        "\n",
        "# Use SelectKBest for numeric features (example for regression on Rating_num)\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "X_num = df_model[['cost_for_two_clipped',\n",
        "                  'Pictures',\n",
        "                  'review_char_len',\n",
        "                  'review_word_count',\n",
        "                  'review_hour']]\n",
        "y = df_model['Rating_num']\n",
        "\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "selector.fit(X_num, y)\n",
        "\n",
        "feature_scores = pd.Series(selector.scores_, index=X_num.columns).sort_values(ascending=False)\n",
        "print(\"\\nSelectKBest scores:\\n\", feature_scores)\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used correlation analysis and SelectKBest (f_regression). Correlation gives a quick view of linear relationships with Rating_num. SelectKBest ranks numeric features based on their statistical relationship with the target, helping to focus on more predictive variables."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, features like cost_for_two_clipped, Pictures, and text-length features (review_word_count, review_char_len) show higher scores or correlations, indicating they help explain rating variation (e.g., longer, picture-rich reviews often correlate with stronger sentiments)."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Transformation\n",
        "# Example: log-transform skewed features\n",
        "df_model['cost_for_two_log'] = np.log1p(df_model['cost_for_two_clipped'])\n",
        "df_model['review_word_count_log'] = np.log1p(df_model['review_word_count'])"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, cost_for_two and review_word_count are likely right-skewed. I used log1p transformation to reduce skewness and stabilize variance, which helps models that assume roughly normal distributions."
      ],
      "metadata": {
        "id": "cuo5y7u19qQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_features_for_model = [\n",
        "    'cost_for_two_log',\n",
        "    'review_word_count_log',\n",
        "    'review_char_len',\n",
        "    'Pictures',\n",
        "    'review_hour'\n",
        "]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_num_scaled = scaler.fit_transform(df_model[num_features_for_model])\n",
        "\n",
        "X_num_scaled[:3]"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used StandardScaler (z-score scaling), which centers features to mean 0 and variance 1. This is helpful for many models (e.g., linear models, KNN, SVM) so that all numeric features are on a comparable scale"
      ],
      "metadata": {
        "id": "9YO3F7Yz94XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For the numeric features alone it’s optional, but if we combine many text features (TF-IDF) plus numeric features, dimensionality reduction (e.g., PCA) can help reduce noise, improve training speed, and make visualization easier."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensionality Reduction (on numeric features as an example)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_num_pca = pca.fit_transform(X_num_scaled)\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used PCA, which is a standard linear technique that projects data into a smaller set of orthogonal components while preserving maximum variance."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data to train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Here I demonstrate regression on Rating_num using numeric features only.\n",
        "X = df_model[num_features_for_model]\n",
        "y = df_model['Rating_num']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,       # 80-20 split\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used an 80-20 split (test_size=0.2), which is a common practice that provides enough data to train the model while keeping a reasonable hold-out set for unbiased evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset\n",
        "\n",
        "# Create a binary classification label: high rating vs others\n",
        "df_model['high_rating'] = (df_model['Rating_num'] >= 4).astype(int)\n",
        "\n",
        "print(\"Class distribution (high_rating):\")\n",
        "print(df_model['high_rating'].value_counts())\n",
        "print(\"\\nClass distribution (proportion):\")\n",
        "print(df_model['high_rating'].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset by creating synthetic samples of the minority class. This avoids simply duplicating rows and helps models learn better decision boundaries for the under-represented class."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for ML Models\n",
        "# -----------------------------\n",
        "# 1. Start from df_final\n",
        "# -----------------------------\n",
        "df_ml = df_final.copy()\n",
        "\n",
        "# Make sure Rating_num is numeric\n",
        "df_ml['Rating_num'] = pd.to_numeric(df_ml['Rating_num'], errors='coerce')\n",
        "\n",
        "# Drop rows without a usable rating\n",
        "df_ml = df_ml.dropna(subset=['Rating_num'])\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Target variable: high vs low rating\n",
        "#    1 = high rating (>=4), 0 = others\n",
        "# -----------------------------\n",
        "df_ml['high_rating'] = (df_ml['Rating_num'] >= 4.0).astype(int)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Basic numeric feature engineering\n",
        "# -----------------------------\n",
        "\n",
        "# Cost: fill missing with median and convert to float if needed\n",
        "df_ml['cost_for_two'] = pd.to_numeric(df_ml['cost_for_two'], errors='coerce')\n",
        "df_ml['cost_for_two'] = df_ml['cost_for_two'].fillna(df_ml['cost_for_two'].median())\n",
        "\n",
        "# Log transform (helps with skewness)\n",
        "df_ml['cost_for_two_log'] = np.log1p(df_ml['cost_for_two'])\n",
        "\n",
        "# Review text features\n",
        "df_ml['Review'] = df_ml['Review'].fillna('')\n",
        "\n",
        "# number of words\n",
        "df_ml['review_word_count'] = df_ml['Review'].str.split().str.len()\n",
        "\n",
        "# number of characters\n",
        "df_ml['review_char_len'] = df_ml['Review'].str.len()\n",
        "\n",
        "# log transform word count\n",
        "df_ml['review_word_count_log'] = np.log1p(df_ml['review_word_count'])\n",
        "\n",
        "# Time-based feature: hour of review\n",
        "df_ml['review_hour'] = df_ml['Time_parsed'].dt.hour\n",
        "\n",
        "# Pictures: ensure no missing\n",
        "df_ml['Pictures'] = df_ml['Pictures'].fillna(0)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Final feature set and target\n",
        "# -----------------------------\n",
        "feature_cols = [\n",
        "    'cost_for_two_log',\n",
        "    'review_word_count_log',\n",
        "    'review_char_len',\n",
        "    'Pictures',\n",
        "    'review_hour'\n",
        "]\n",
        "\n",
        "X = df_ml[feature_cols]\n",
        "y = df_ml['high_rating']\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Train–test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Evaluation helpers\n",
        "# -----------------------------\n",
        "def evaluate_model(y_true, y_pred, y_proba, model_name=\"Model\"):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1-score': f1,\n",
        "        'ROC-AUC': auc\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} Metrics:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_metric_bar(metrics_dict, title):\n",
        "    names = list(metrics_dict.keys())\n",
        "    values = list(metrics_dict.values())\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(names, values)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "    for i, v in enumerate(values):\n",
        "        plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', fontsize=9)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "N3FaOmBEgkJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1\n",
        "# 1 Implementation: Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(\n",
        "        class_weight='balanced',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 2. Fit the Algorithm\n",
        "log_reg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 3. Predict on the model\n",
        "y_pred_lr = log_reg_pipeline.predict(X_test)\n",
        "y_proba_lr = log_reg_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 4. Evaluate\n",
        "lr_metrics = evaluate_model(y_test, y_pred_lr, y_proba_lr, \"Logistic Regression\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2xHx4qxgnxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.Visualizing evaluation Metric Score chart\n",
        "plot_metric_bar(lr_metrics, \"Logistic Regression - Evaluation Metrics\")"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I used Logistic Regression, a linear classification model that estimates the probability of a review being “high rating” (≥4 stars) based on numeric features like cost, review length and time. The metric chart summarises accuracy, precision, recall, F1-score and ROC-AUC on the test set. Together these show how well the model balances correct positive predictions and avoids misclassifying low-rating reviews as high."
      ],
      "metadata": {
        "id": "mhRn1HnchTuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1\n",
        "#  Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "param_grid_lr = {\n",
        "    'clf__C': [0.01, 0.1, 1, 10],\n",
        "    'clf__penalty': ['l2']\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(\n",
        "    estimator=log_reg_pipeline,\n",
        "    param_grid=param_grid_lr,\n",
        "    scoring='f1',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters (Logistic Regression):\", grid_lr.best_params_)\n",
        "print(\"Best CV F1-score:\", grid_lr.best_score_)\n",
        "\n",
        "# Predict on the best model\n",
        "best_lr = grid_lr.best_estimator_\n",
        "y_pred_lr_tuned = best_lr.predict(X_test)\n",
        "y_proba_lr_tuned = best_lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "lr_metrics_tuned = evaluate_model(\n",
        "    y_test, y_pred_lr_tuned, y_proba_lr_tuned,\n",
        "    \"Logistic Regression (Tuned)\"\n",
        ")\n",
        "\n",
        "# Visualizing updated evaluation Metric Score chart\n",
        "plot_metric_bar(lr_metrics_tuned, \"Logistic Regression (Tuned) - Evaluation Metrics\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I used GridSearchCV for hyperparameter optimization of the Logistic Regression model. GridSearchCV performs an exhaustive search over a predefined grid of hyperparameters (here, different values of C and penalty='l2') combined with k-fold cross-validation (cv=5).\n",
        "\n",
        "I chose this technique because:\n",
        "\n",
        "It gives a systematic and reproducible way to evaluate multiple hyperparameter combinations.\n",
        "\n",
        "Using F1-score as the scoring metric focuses on balancing precision and recall, which is important for this problem where correctly identifying high-rating reviews is more important than raw accuracy alone.\n",
        "\n",
        "Cross-validation helps obtain a more robust estimate of model performance compared to a single train–test split, reducing the risk of overfitting to a particular split."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is an improvement after tuning the Logistic Regression model.\n",
        "\n",
        "The best configuration found by GridSearchCV was:\n",
        "C = 0.01, penalty = 'l2', with a CV F1-score of ~0.6468.\n",
        "\n",
        "On the test set, the tuned model achieved:\n",
        "\n",
        "Accuracy: 0.6076\n",
        "\n",
        "Precision: 0.7307\n",
        "\n",
        "Recall: 0.5968\n",
        "\n",
        "F1-score: 0.6570\n",
        "\n",
        "ROC-AUC: 0.6392\n",
        "\n",
        "Compared to the baseline (untuned) Logistic Regression (shown in the earlier metric chart), the tuned model provides a higher F1-score and better overall balance between precision and recall, while keeping accuracy at a similar level.\n",
        "\n",
        "In the updated evaluation metric score chart, the tuned Logistic Regression bar shows a notable increase in F1-score and ROC-AUC, indicating that hyperparameter tuning helped the model capture the “high_rating” class more effectively and generalize better to unseen data."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model – 2: Random Forest\n",
        "# 1. Implementation\n",
        "\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 2.Fit the Algorithm\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# 3.Predict on the model\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "y_proba_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 4.Evaluate\n",
        "rf_metrics = evaluate_model(y_test, y_pred_rf, y_proba_rf, \"Random Forest\")\n",
        "\n",
        "# 5.Visualizing evaluation Metric Score chart\n",
        "plot_metric_bar(rf_metrics, \"Random Forest - Evaluation Metrics\")\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a Random Forest Classifier, which combines many decision trees trained on bootstrapped samples and random subsets of features. It captures non-linear relationships between cost, review behaviour and ratings. The metric chart again summarises accuracy, precision, recall, F1, and ROC-AUC. Compared to Logistic Regression, Random Forest often improves recall/F1 by modelling interactions between features."
      ],
      "metadata": {
        "id": "3KnOx7BDiLc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Random Forest\n",
        "# Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        class_weight='balanced',\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    param_grid=param_grid_rf,\n",
        "    scoring='f1',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters (Random Forest):\", grid_rf.best_params_)\n",
        "print(\"Best CV F1-score:\", grid_rf.best_score_)\n",
        "\n",
        "# Predict on the best model\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf_tuned = best_rf.predict(X_test)\n",
        "y_proba_rf_tuned = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "rf_metrics_tuned = evaluate_model(\n",
        "    y_test, y_pred_rf_tuned, y_proba_rf_tuned,\n",
        "    \"Random Forest (Tuned)\"\n",
        ")\n",
        "\n",
        "# Visualizing updated evaluation Metric Score chart\n",
        "plot_metric_bar(rf_metrics_tuned, \"Random Forest (Tuned) - Evaluation Metrics\")\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, I used GridSearchCV, but only over a small set of key hyperparameters: number of trees, maximum depth, and minimum samples to split. These strongly control overfitting vs. underfitting, and a compact grid keeps runtime manageable."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I compare the F1-score and ROC-AUC before and after tuning. An improvement usually means the forest is now deep enough and large enough to capture patterns, but not so complex that it overfits."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Gradient BoostingImplementation\n",
        "\n",
        "# 1. Implementation\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2.Fit the Algorithm\n",
        "gb_clf.fit(X_train, y_train)\n",
        "\n",
        "# 3.Predict on the model\n",
        "y_pred_gb = gb_clf.predict(X_test)\n",
        "y_proba_gb = gb_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 4.Evaluate\n",
        "gb_metrics = evaluate_model(y_test, y_pred_gb, y_proba_gb, \"Gradient Boosting\")\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.Visualizing evaluation Metric Score chart\n",
        "plot_metric_bar(gb_metrics, \"Gradient Boosting - Evaluation Metrics\")"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I used Gradient Boosting, a boosting ensemble that builds trees sequentially, each correcting the errors of the previous ones. It is powerful on tabular data and can capture complex non-linear patterns. The metric chart shows how well it distinguishes high-rating vs. lower-rating reviews; often Gradient Boosting gives strong F1 and ROC-AUC on structured data."
      ],
      "metadata": {
        "id": "SITUuG7SirJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Gradient Boosting\n",
        "\n",
        "#  Cross-Validation & Hyperparameter Tuning\n",
        "\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'max_depth': [3, 4]\n",
        "}\n",
        "\n",
        "grid_gb = GridSearchCV(\n",
        "    estimator=GradientBoostingClassifier(random_state=42),\n",
        "    param_grid=param_grid_gb,\n",
        "    scoring='f1',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_gb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters (Gradient Boosting):\", grid_gb.best_params_)\n",
        "print(\"Best CV F1-score:\", grid_gb.best_score_)\n",
        "\n",
        "# Predict on the best model\n",
        "best_gb = grid_gb.best_estimator_\n",
        "y_pred_gb_tuned = best_gb.predict(X_test)\n",
        "y_proba_gb_tuned = best_gb_tuned = best_gb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "gb_metrics_tuned = evaluate_model(\n",
        "    y_test, y_pred_gb_tuned, y_proba_gb_tuned,\n",
        "    \"Gradient Boosting (Tuned)\"\n",
        ")\n",
        "\n",
        "# Visualizing updated evaluation Metric Score chart\n",
        "plot_metric_bar(gb_metrics_tuned, \"Gradient Boosting (Tuned) - Evaluation Metrics\")\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV over n_estimators, learning_rate, and max_depth. These control how many boosting steps we take, how aggressively we correct errors, and how complex each tree is. A small grid gives a good trade-off between performance and compute time."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Comparing pre- and post-tuning F1/ROC-AUC shows whether the boosted model generalises better. Usually, fine-tuning learning rate and tree depth helps avoid both underfitting and overfitting."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I focused on F1-score and ROC-AUC as the primary metrics, with precision, recall, and accuracy as supporting metrics.\n",
        "\n",
        "From a business perspective, misclassifying a low-rating review as high can mislead management, while missing genuine high-rating patterns also hurts. F1-score balances precision and recall and is more informative than accuracy when class distribution is skewed.\n",
        "\n",
        "ROC-AUC measures the model’s ability to rank high-rating reviews above low-rating ones across thresholds, which is important if the business later wants to tune the cut-off for campaigns or alerts."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I compared the three models on the test set and selected the one with the best trade-off of F1-score and ROC-AUC (typically a tree-based model like Random Forest or Gradient Boosting). These models capture non-linear relationships between cost, review patterns and ratings, and tend to be more robust to feature interactions than a simple linear model. I also considered model stability (cross-validation scores) and interpretability (feature importances) while choosing the final model."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance for Random Forest (best_rf)\n",
        "\n",
        "importances = best_rf.feature_importances_\n",
        "fi_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': importances\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(fi_df)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(fi_df['feature'], fi_df['importance'])\n",
        "plt.title(\"Random Forest - Feature Importances\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N9pYe9bGjagI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the final model, I inspected feature importances from the Random Forest. Features such as cost_for_two_log, review_word_count_log, and Pictures had the highest importance scores. This suggests that pricing level, depth of the review, and use of images are key drivers of high ratings. These insights are business-relevant because they indicate levers (e.g., menu pricing, encouraging rich reviews and photos) that Zomato or restaurant partners can influence to improve perceived quality."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "# 8.1 Save the best performing ML model for deployment\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Assuming best_lr is the best model from GridSearchCV\n",
        "model_filename = \"best_logistic_regression_zomato.joblib\"\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(best_lr, model_filename)\n",
        "\n",
        "print(f\"Model saved successfully as: {model_filename}\")\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle_filename = \"best_logistic_regression_zomato.pkl\"\n",
        "\n",
        "with open(pickle_filename, \"wb\") as f:\n",
        "    pickle.dump(best_lr, f)\n",
        "\n",
        "print(f\"Model also saved as: {pickle_filename}\")\n"
      ],
      "metadata": {
        "id": "QEwiKZ8e1aAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 1. LOAD THE MODEL --------\n",
        "model_filename = \"best_logistic_regression_zomato.joblib\"  # use the exact name you saved\n",
        "loaded_model = joblib.load(model_filename)\n",
        "\n",
        "print(f\"Loaded model from: {model_filename}\")\n",
        "\n",
        "# -------- 2. SANITY CHECK ON UNSEEN TEST DATA --------\n",
        "# Make sure X_test and y_test are already defined from your train_test_split step\n",
        "\n",
        "# Take a small unseen sample from the test set\n",
        "X_unseen = X_test.sample(5, random_state=42)\n",
        "y_unseen_true = y_test.loc[X_unseen.index]\n",
        "\n",
        "# Predict using the loaded model\n",
        "y_unseen_pred = loaded_model.predict(X_unseen)\n",
        "y_unseen_proba = loaded_model.predict_proba(X_unseen)[:, 1]\n",
        "\n",
        "# Create a small comparison table\n",
        "results_unseen = X_unseen.copy()\n",
        "results_unseen['true_high_rating'] = y_unseen_true.values\n",
        "results_unseen['pred_high_rating'] = y_unseen_pred\n",
        "results_unseen['pred_probability_high'] = y_unseen_proba\n",
        "\n",
        "print(\"\\nSanity check on unseen test samples:\")\n",
        "print(results_unseen)\n"
      ],
      "metadata": {
        "id": "icg21Dov332O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "total_seconds = end_time - notebook_start_time\n",
        "mins = total_seconds / 60\n",
        "\n",
        "print(f\"\\nNotebook finished.\")\n",
        "print(f\"Total execution time: {total_seconds:.2f} seconds ({mins:.2f} minutes)\")\n"
      ],
      "metadata": {
        "id": "_vLYvp9NTAYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project demonstrates how restaurant and review data from Zomato can be transformed into meaningful business insights and predictive models. Through systematic EDA, we identified important trends across cities, cuisines, pricing levels, ratings, and review behaviour. These patterns can guide decisions such as which segments to target, where to expand, and how to position restaurants in different markets.\n",
        "\n",
        "The sentiment classification model further adds value by automatically categorising customer reviews, enabling scalable monitoring of customer satisfaction and early detection of service or quality issues. Although there is room for improvement through richer feature engineering and more advanced NLP models, the current approach provides a solid baseline.\n",
        "\n",
        "Overall, the project shows the end-to-end workflow of a practical data science solution—from data cleaning and visualisation to model building and evaluation—using real-world Zomato data. It highlights how data-driven approaches can support better decision-making for food delivery platforms, restaurant partners, and ultimately the customers who rely on them.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}